{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/facebookresearch/segment-anything.git >> None","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-23T20:56:24.893956Z","iopub.execute_input":"2023-10-23T20:56:24.894683Z","iopub.status.idle":"2023-10-23T20:56:40.984761Z","shell.execute_reply.started":"2023-10-23T20:56:24.894648Z","shell.execute_reply":"2023-10-23T20:56:40.979260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-python pycocotools matplotlib onnxruntime onnx >> None","metadata":{"execution":{"iopub.status.busy":"2023-10-23T20:56:40.987716Z","iopub.execute_input":"2023-10-23T20:56:40.988169Z","iopub.status.idle":"2023-10-23T20:56:55.154931Z","shell.execute_reply.started":"2023-10-23T20:56:40.988124Z","shell.execute_reply":"2023-10-23T20:56:55.153602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom typing import List\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T12:00:00.423904Z","iopub.execute_input":"2023-10-24T12:00:00.424285Z","iopub.status.idle":"2023-10-24T12:00:00.429789Z","shell.execute_reply.started":"2023-10-24T12:00:00.424254Z","shell.execute_reply":"2023-10-24T12:00:00.428984Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T09:13:30.505364Z","iopub.execute_input":"2023-10-24T09:13:30.506335Z","iopub.status.idle":"2023-10-24T09:13:30.510793Z","shell.execute_reply.started":"2023-10-24T09:13:30.506303Z","shell.execute_reply":"2023-10-24T09:13:30.509363Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\n!mkdir {HOME}/weights\n%cd {HOME}/weights\n\n!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n\nCHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T09:13:34.479356Z","iopub.execute_input":"2023-10-24T09:13:34.480284Z","iopub.status.idle":"2023-10-24T09:13:45.729108Z","shell.execute_reply.started":"2023-10-24T09:13:34.480235Z","shell.execute_reply":"2023-10-24T09:13:45.727720Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/weights\n","output_type":"stream"}]},{"cell_type":"code","source":"VIDEO_PATH = # YOUR VIDEO                   \"/kaggle/input/sam-da/diff/traffic_(720p).mp4\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T12:01:05.060316Z","iopub.execute_input":"2023-10-24T12:01:05.060981Z","iopub.status.idle":"2023-10-24T12:01:05.065196Z","shell.execute_reply.started":"2023-10-24T12:01:05.060948Z","shell.execute_reply":"2023-10-24T12:01:05.064205Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2023-10-24T09:13:45.740043Z","iopub.execute_input":"2023-10-24T09:13:45.740473Z","iopub.status.idle":"2023-10-24T09:13:45.829927Z","shell.execute_reply.started":"2023-10-24T09:13:45.740438Z","shell.execute_reply":"2023-10-24T09:13:45.828773Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"class SamVideoMasker:\n    def __init__(\n        self,\n        checkpoint_path: str = CHECKPOINT_PATH, \n        device: torch.device = DEVICE,\n        *args, **kwargs\n    ):\n        \"\"\"Init SamAutomaticMaskGenerator model, load checkpoint, and put it on device\n        Parameters\n        ----------\n        checkpoint_path: str\n            path to model checkpoint\n        device: torch.device\n            device\n        args, kwargs:\n            model parameters for tuning\n        \"\"\"\n\n        sam = sam_model_registry[\"vit_h\"](checkpoint=checkpoint_path)\n        sam.to(device=device)\n        \n        self.mask_generator = SamAutomaticMaskGenerator(model=sam, *args, **kwargs)\n    \n    @staticmethod\n    def _read_video(video_path: str):\n        \"\"\"Capture video and reads it by frames\n\n        Parameters\n        ----------\n        video_path : str\n            path to video\n\n        Returns\n        -------\n        frames: List[np.ndarray]\n            list of video frames\n        \"\"\"\n        cap = cv2.VideoCapture(video_path)\n        \n        if cap.isOpened() is False: \n            raise Exception(\"Error opening video stream or file\")\n        \n        frames = []\n        while cap.isOpened():\n            ret, frame = cap.read()\n            if ret is True:\n                frames.append(frame)\n            else:\n                break\n                \n        cap.release()     \n        \n        return frames\n                \n    def _generate_image_masks(self, image: np.ndarray):\n        \"\"\"Generate masks for input image\n\n        Parameters\n        ----------\n        image : np.ndarray\n            input image\n\n        Returns\n        -------\n        image_masks: List[dict]\n            List over masks, where each mask is a dictionary containing various data about the mask. \n            These keys are:\n                segmentation : the mask\n                area : the area of the mask in pixels\n                bbox : the boundary box of the mask in XYWH format\n                predicted_iou : the model's own prediction for the quality of the mask\n                point_coords : the sampled input point that generated this mask\n                stability_score : an additional measure of mask quality\n                crop_box : the crop of the image used to generate this mask in XYWH format\n        \"\"\"\n        image_masks = self.mask_generator.generate(image)\n        return image_masks\n    \n    def _generate_video_frames_masks(self, frames: List[np.ndarray], show_progress: bool=True):\n        \"\"\"Generate masks for input image\n\n        Parameters\n        ----------\n        frames : List[np.ndarray]\n            list of video frames\n        show_progress: bool\n            show progress bar, by default = True\n\n        Returns\n        -------\n        frames_masks_: List[List[dict]]\n            List with frames masks\n        \"\"\"\n        self.frames_masks_ = []\n        for frame in tqdm(frames, desc='masks generation', disable=not show_progress):\n            masks = self._generate_image_masks(frame)\n            self.frames_masks_.append(masks)\n    \n    @staticmethod\n    def _get_masked_image(\n        image: np.ndarray, \n        image_masks: List[dict], \n        alpha: float, \n        beta: float, \n        gamma: float,\n        palette_size: int,\n    ):\n        \"\"\"Blending original image and its masks\n\n        Returns\n        -------\n        masked_image: np.ndarray\n            masked image\n        \"\"\"\n        palette = tuple(sns.husl_palette(palette_size))\n        pixel_count = image.shape[0] * image.shape[1]\n        \n        sorted_masks = sorted(image_masks, key=(lambda x: x['area']), reverse=True)\n        img = np.zeros_like(image)\n        \n        for mask in sorted_masks:\n            m = mask['segmentation']\n            area = mask['area']\n            color_idx = int(np.log(pixel_count / area ) * palette_size / 10) % palette_size\n            color_mask = np.uint8(np.array(palette[color_idx]) * 255)\n            img[m] = color_mask\n            \n        img[img == 0] = image[img == 0]\n        masked_image = cv2.addWeighted(image, alpha, img, beta, gamma)\n        \n        return masked_image\n    \n    def _get_masked_frames(\n        self, \n        frames: List[np.ndarray],\n        frames_masks: List[List[dict]], \n        alpha: float,\n        beta: float,\n        gamma: float,\n        palette_size: int, \n        show_progress: bool=True\n    ):\n        \"\"\"Blending original image and its masks\n\n        Returns\n        -------\n        masked_frames: List[np.ndarray]\n            List of masked frames\n        \"\"\"        \n        masked_frames = []\n        for frame, frame_masks in tqdm(\n            zip(frames, frames_masks),\n            total = len(frames),\n            desc='masked frames processing', \n            disable=not show_progress\n        ):\n            masked_image = self._get_masked_image(frame, frame_masks, alpha, beta, gamma, palette_size)\n            masked_frames.append(masked_image)\n        \n        return masked_frames\n    \n    def create_video_with_mask(\n        self, \n        orig_video_path: str, \n        out_filename: str=\"masked_video.avi\", \n        fps: int=15, \n        alpha: float=0.65, \n        beta: float=0.35, \n        gamma: float=0, \n        palette_size: int=100,\n        show_progress: bool=True,\n    ):\n        \"\"\"Create masked video\n\n        Parameters\n        ----------\n        orig_video_path: str\n            path to original video\n        out_filename: str\n            name of the output video file\n        fps: int\n            framerate of the created video stream, by default=15\n        alpha: float\n            image blending coef [0.0-1.0], by default 0.55 \n        beta: float\n            mask blending coef equal 1 - alpha, by default 0.45\n        gamma: float\n            gamma\n        palette_size: int\n            palette size, by default 100\n        show_progress: bool\n            show progress bar, by default = True\n        \"\"\"\n        frames = self._read_video(orig_video_path)\n        self._generate_video_frames_masks(frames, show_progress=show_progress)\n        masked_frames = self._get_masked_frames(frames, self.frames_masks_, alpha, beta, gamma, palette_size, show_progress)\n        \n        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n        frame_size = frames[0].shape[1], frames[0].shape[0]\n        out = cv2.VideoWriter(out_filename, fourcc, fps, frame_size)\n        \n        for frame in masked_frames:\n            out.write(frame)\n        out.release()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-24T12:24:42.141338Z","iopub.execute_input":"2023-10-24T12:24:42.141695Z","iopub.status.idle":"2023-10-24T12:24:42.166304Z","shell.execute_reply.started":"2023-10-24T12:24:42.141667Z","shell.execute_reply":"2023-10-24T12:24:42.165221Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"%%time\nsam_video_masker = SamVideoMasker()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T12:24:42.595376Z","iopub.execute_input":"2023-10-24T12:24:42.595880Z","iopub.status.idle":"2023-10-24T12:24:48.494959Z","shell.execute_reply.started":"2023-10-24T12:24:42.595840Z","shell.execute_reply":"2023-10-24T12:24:48.493990Z"},"trusted":true},"execution_count":189,"outputs":[{"name":"stdout","text":"CPU times: user 5.32 s, sys: 871 ms, total: 6.19 s\nWall time: 5.89 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nsam_video_masker.create_video_with_mask(VIDEO_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T12:24:48.496860Z","iopub.execute_input":"2023-10-24T12:24:48.497320Z","iopub.status.idle":"2023-10-24T12:28:21.098168Z","shell.execute_reply.started":"2023-10-24T12:24:48.497284Z","shell.execute_reply":"2023-10-24T12:28:21.097202Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stderr","text":"masks generation: 100%|██████████| 20/20 [03:25<00:00, 10.27s/it]\nmasked frames processing: 100%|██████████| 20/20 [00:06<00:00,  3.12it/s]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 3min 33s, sys: 162 ms, total: 3min 33s\nWall time: 3min 32s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}